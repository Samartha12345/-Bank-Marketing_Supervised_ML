{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a685c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_49524\\525566892.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.job.fillna('admin',inplace=True)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_49524\\525566892.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.marital.fillna('married',inplace=True)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_49524\\525566892.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.default.fillna('no',inplace=True)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_49524\\525566892.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.housing.fillna('yes',inplace=True)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_49524\\525566892.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.loan.fillna('no',inplace=True)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_49524\\525566892.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.education.fillna('university.degree',inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7065  250]\n",
      " [ 450  473]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      7315\n",
      "           1       0.65      0.51      0.57       923\n",
      "\n",
      "    accuracy                           0.92      8238\n",
      "   macro avg       0.80      0.74      0.76      8238\n",
      "weighted avg       0.91      0.92      0.91      8238\n",
      "\n",
      "           Feature    Importance\n",
      "10        duration  3.224916e-01\n",
      "18       euribor3m  1.088398e-01\n",
      "0              age  9.676307e-02\n",
      "19     nr.employed  7.056153e-02\n",
      "1              job  5.063189e-02\n",
      "11        campaign  4.342989e-02\n",
      "9      day_of_week  4.191917e-02\n",
      "3        education  4.028164e-02\n",
      "14        poutcome  3.126136e-02\n",
      "12           pdays  2.816091e-02\n",
      "17   cons.conf.idx  2.654827e-02\n",
      "2          marital  2.370926e-02\n",
      "16  cons.price.idx  2.009741e-02\n",
      "15    emp.var.rate  1.962132e-02\n",
      "8            month  1.938374e-02\n",
      "5          housing  1.874884e-02\n",
      "13        previous  1.464531e-02\n",
      "6             loan  1.281241e-02\n",
      "7          contact  1.009250e-02\n",
      "4          default  7.752689e-08\n",
      "Before Using SMOTE, counts of label '1': 3717\n",
      "Before Using SMOTE, counts of label '0': 29233 \n",
      "\n",
      "After Using SMOTE, counts of label '1': 29233\n",
      "After Using SMOTE, counts of label '0': 29233 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\Dell\\Desktop\\bank.csv\",sep=\";\")\n",
    "\n",
    "df.isnull().sum()[df.isnull().sum()>0]\n",
    "\n",
    "import numpy as np\n",
    "df.replace({'unknown':np.nan},inplace=True)\n",
    "\n",
    "df.isnull().sum()[df.isnull().sum()>0]\n",
    "\n",
    "df.job.fillna('admin',inplace=True)\n",
    "df.marital.fillna('married',inplace=True)\n",
    "df.default.fillna('no',inplace=True)\n",
    "df.housing.fillna('yes',inplace=True)\n",
    "df.loan.fillna('no',inplace=True)\n",
    "df.education.fillna('university.degree',inplace=True)\n",
    "\n",
    "df.isnull().sum()[df.isnull().sum()>0]\n",
    "\n",
    "# Label Encoding wherever required\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['job'] = le.fit_transform(df['job'])\n",
    "df['marital'] = le.fit_transform(df['marital'])\n",
    "df['education'] = le.fit_transform(df['education'])\n",
    "df['housing'] = le.fit_transform(df['housing'])\n",
    "df['loan'] = le.fit_transform(df['loan'])\n",
    "df['contact'] = le.fit_transform(df['contact'])\n",
    "df['month'] = le.fit_transform(df['month'])\n",
    "df['day_of_week'] = le.fit_transform(df['day_of_week'])\n",
    "df['poutcome'] = le.fit_transform(df['poutcome'])\n",
    "df['default'] = le.fit_transform(df['default'])\n",
    "df['y'] = le.fit_transform(df['y'])\n",
    "\n",
    "## Selecting important features based on Random Forest\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train , df_test = train_test_split(df , test_size= .2)\n",
    "\n",
    "df_train_x = df_train.iloc[ : , 0:-1] \n",
    "df_train_y = df_train.iloc[ : , -1]\n",
    "\n",
    "df_test_x = df_test.iloc[ : , 0:-1] \n",
    "df_test_y = df_test.iloc[: , -1]\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf  = RandomForestClassifier()\n",
    "rf.fit(df_train_x,df_train_y)\n",
    "pred_rf = rf.predict(df_test_x)\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "tab_rf = confusion_matrix(df_test_y,pred_rf)\n",
    "print(tab_rf)\n",
    "print(classification_report(df_test_y,pred_rf))\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "feature_names = df_train_x.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feature_importance_df\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(feature_importance_df)\n",
    "\n",
    "top_features = feature_importance_df['Feature'][:10].values\n",
    "selected_features = ['duration', 'euribor3m', 'age', 'nr.employed', \n",
    "                     'job', 'education', 'campaign', 'day_of_week', \n",
    "                     'pdays', 'cons.conf.idx']\n",
    "\n",
    "\n",
    "train_df_x_selected = df_train[selected_features]  \n",
    "test_df_x_selected = df_test[selected_features]\n",
    "\n",
    "\n",
    "train_df_y = df_train.iloc[:, -1]  # Last column is the target\n",
    "test_df_y = df_test.iloc[:, -1]\n",
    "\n",
    "test_df_y = df_test.iloc[:, -1]\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "train_df_x_selected = df_train[selected_features]  \n",
    "train_df_y = df_train.iloc[:, -1]  \n",
    "\n",
    "sm = SMOTE()\n",
    "\n",
    "\n",
    "x_train_resampled, y_train_resampled = sm.fit_resample(train_df_x_selected, train_df_y)\n",
    "\n",
    "\n",
    "print(\"Before Using SMOTE, counts of label '1': {}\".format(sum(train_df_y == 1)))\n",
    "print(\"Before Using SMOTE, counts of label '0': {} \\n\".format(sum(train_df_y == 0)))\n",
    "print(\"After Using SMOTE, counts of label '1': {}\".format(sum(y_train_resampled == 1)))\n",
    "print(\"After Using SMOTE, counts of label '0': {} \\n\".format(sum(y_train_resampled == 0)))\n",
    "\n",
    "\n",
    "## Standardize the data using any one of the scalers provided by sklearn\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train_resampled = scaler.fit_transform(x_train_resampled)\n",
    "x_test_standardized = scaler.transform(test_df_x_selected)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10044467",
   "metadata": {},
   "source": [
    "### Tabulate the performance metrics of all the above models, perform tuning of models and tell which model performs better in predicting if the client will subscribe to term deposit or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61374f71",
   "metadata": {},
   "source": [
    "### 1.Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bacd1081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Parameters: {'C': 10, 'solver': 'liblinear'}\n",
      "Best Precision Score for Logistic Regression: 0.8480444973002399\n",
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.8492352512745812\n",
      "Precision: 0.4146602461209203\n",
      "Recall: 0.8396533044420368\n",
      "F1-Score: 0.5551575931232091\n",
      "Confusion Matrix:\n",
      "[[6221 1094]\n",
      " [ 148  775]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      7315\n",
      "           1       0.41      0.84      0.56       923\n",
      "\n",
      "    accuracy                           0.85      8238\n",
      "   macro avg       0.70      0.85      0.73      8238\n",
      "weighted avg       0.91      0.85      0.87      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "\n",
    "param_grid_logreg = {\n",
    "    'C': [0.1, 1, 10],  # Regularization strength\n",
    "    'solver': ['liblinear']  # Solvers\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_logreg = GridSearchCV(logreg, param_grid_logreg, scoring='precision', cv=5)\n",
    "grid_search_logreg.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "\n",
    "best_logreg_params = grid_search_logreg.best_params_\n",
    "best_logreg_score = grid_search_logreg.best_score_\n",
    "\n",
    "\n",
    "print(f\"Best Logistic Regression Parameters: {best_logreg_params}\")\n",
    "print(f\"Best Precision Score for Logistic Regression: {best_logreg_score}\")\n",
    "\n",
    "\n",
    "best_logreg = grid_search_logreg.best_estimator_\n",
    "\n",
    "\n",
    "y_pred_logreg = best_logreg.predict(x_test_standardized)\n",
    "\n",
    "\n",
    "accuracy_logreg = best_logreg.score(x_test_standardized, test_df_y)\n",
    "precision_logreg = precision_score(test_df_y, y_pred_logreg)\n",
    "recall_logreg = recall_score(test_df_y, y_pred_logreg)\n",
    "f1_logreg = f1_score(test_df_y, y_pred_logreg)\n",
    "conf_matrix_logreg = confusion_matrix(test_df_y, y_pred_logreg)\n",
    "class_report_logreg = classification_report(test_df_y, y_pred_logreg)\n",
    "\n",
    "\n",
    "print(\"\\nLogistic Regression Performance:\")\n",
    "print(f\"Accuracy: {accuracy_logreg}\")\n",
    "print(f\"Precision: {precision_logreg}\")\n",
    "print(f\"Recall: {recall_logreg}\")\n",
    "print(f\"F1-Score: {f1_logreg}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_logreg)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report_logreg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34dec98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree Parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Best Precision Score for Decision Tree: 0.9298691402786188\n",
      "\n",
      "Decision Tree Performance:\n",
      "Accuracy: 0.8895362952172857\n",
      "Precision: 0.5067920585161965\n",
      "Recall: 0.5254604550379198\n",
      "F1-Score: 0.5159574468085106\n",
      "Confusion Matrix:\n",
      "[[6843  472]\n",
      " [ 438  485]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      7315\n",
      "           1       0.51      0.53      0.52       923\n",
      "\n",
      "    accuracy                           0.89      8238\n",
      "   macro avg       0.72      0.73      0.73      8238\n",
      "weighted avg       0.89      0.89      0.89      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "\n",
    "param_grid_dtc = {\n",
    "    'max_depth': [10, 20, 30, None],  # Maximum depth of tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum samples required at leaf node\n",
    "    'criterion': ['gini', 'entropy']  # Split criteria\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_dtc = GridSearchCV(dtc, param_grid_dtc, scoring='precision', cv=5)\n",
    "grid_search_dtc.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "\n",
    "best_dtc_params = grid_search_dtc.best_params_\n",
    "best_dtc_score = grid_search_dtc.best_score_\n",
    "\n",
    "print(f\"Best Decision Tree Parameters: {best_dtc_params}\")\n",
    "print(f\"Best Precision Score for Decision Tree: {best_dtc_score}\")\n",
    "\n",
    "\n",
    "best_dtc = grid_search_dtc.best_estimator_\n",
    "\n",
    "\n",
    "y_pred_dtc = best_dtc.predict(x_test_standardized)\n",
    "\n",
    "\n",
    "accuracy_dtc = best_dtc.score(x_test_standardized, test_df_y)\n",
    "precision_dtc = precision_score(test_df_y, y_pred_dtc)\n",
    "recall_dtc = recall_score(test_df_y, y_pred_dtc)\n",
    "f1_dtc = f1_score(test_df_y, y_pred_dtc)\n",
    "conf_matrix_dtc = confusion_matrix(test_df_y, y_pred_dtc)\n",
    "class_report_dtc = classification_report(test_df_y, y_pred_dtc)\n",
    "\n",
    "\n",
    "print(\"\\nDecision Tree Performance:\")\n",
    "print(f\"Accuracy: {accuracy_dtc}\")\n",
    "print(f\"Precision: {precision_dtc}\")\n",
    "print(f\"Recall: {recall_dtc}\")\n",
    "print(f\"F1-Score: {f1_dtc}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_dtc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report_dtc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf824184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 20, 'criterion': 'gini'}\n",
      "Best Precision Score for Random Forest: 0.9282491390245059\n",
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.9056809905316825\n",
      "Precision: 0.5627147766323024\n",
      "Recall: 0.7096424702058505\n",
      "F1-Score: 0.6276952563488261\n",
      "Confusion Matrix:\n",
      "[[6806  509]\n",
      " [ 268  655]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      7315\n",
      "           1       0.56      0.71      0.63       923\n",
      "\n",
      "    accuracy                           0.91      8238\n",
      "   macro avg       0.76      0.82      0.79      8238\n",
      "weighted avg       0.92      0.91      0.91      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "param_grid_rfc = {\n",
    "    'n_estimators': [50, 100],  # Fewer estimators\n",
    "    'max_depth': [10, 20],  # Reduced depth range\n",
    "    'min_samples_split': [2, 5],  # Reduced options\n",
    "    'min_samples_leaf': [1, 2],  # Reduced options\n",
    "    'criterion': ['gini']  # Keeping only one criterion\n",
    "}\n",
    "\n",
    "\n",
    "random_search_rfc = RandomizedSearchCV(rfc, param_grid_rfc, n_iter=10, scoring='precision', cv=3, n_jobs=-1, random_state=42)\n",
    "random_search_rfc.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "\n",
    "best_rfc_params = random_search_rfc.best_params_\n",
    "best_rfc_score = random_search_rfc.best_score_\n",
    "\n",
    "print(f\"Best Random Forest Parameters: {best_rfc_params}\")\n",
    "print(f\"Best Precision Score for Random Forest: {best_rfc_score}\")\n",
    "\n",
    "\n",
    "best_rfc = random_search_rfc.best_estimator_\n",
    "\n",
    "\n",
    "y_pred_rfc = best_rfc.predict(x_test_standardized)\n",
    "\n",
    "\n",
    "accuracy_rfc = best_rfc.score(x_test_standardized, test_df_y)\n",
    "precision_rfc = precision_score(test_df_y, y_pred_rfc)\n",
    "recall_rfc = recall_score(test_df_y, y_pred_rfc)\n",
    "f1_rfc = f1_score(test_df_y, y_pred_rfc)\n",
    "conf_matrix_rfc = confusion_matrix(test_df_y, y_pred_rfc)\n",
    "class_report_rfc = classification_report(test_df_y, y_pred_rfc)\n",
    "\n",
    "\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "print(f\"Accuracy: {accuracy_rfc}\")\n",
    "print(f\"Precision: {precision_rfc}\")\n",
    "print(f\"Recall: {recall_rfc}\")\n",
    "print(f\"F1-Score: {f1_rfc}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_rfc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report_rfc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7be190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
